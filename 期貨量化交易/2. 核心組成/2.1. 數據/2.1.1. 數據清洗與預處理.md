# 2.1.1. 數據清洗與預處理

在期貨量化交易中，數據是策略的基石。然而，原始數據往往充滿噪音、錯誤和不一致性。因此，[[2. 核心組成/2.1. 數據 (Data)|數據清洗與預處理]]是確保數據質量、避免「垃圾進，垃圾出」的關鍵步驟。

## 常見的數據問題

1.  **缺失值 (Missing Values)**：數據點的遺失，可能由於數據採集失敗、傳輸錯誤或市場休市等原因。
2.  **異常值 (Outliers)**：明顯偏離正常範圍的數據點，可能是數據錄入錯誤、極端市場事件或數據傳輸故障導致。
3.  **重複值 (Duplicate Values)**：同一數據點被記錄多次。
4.  **數據不一致 (Inconsistent Data)**：不同來源或不同時間點的數據格式、單位或定義不統一。
5.  **時間戳問題 (Timestamp Issues)**：時間戳不連續、亂序或時區錯誤。
6.  **合約展期問題 (Roll-over Issues)**：期貨合約有到期日，需要將不同月份的合約數據平滑地銜接起來，形成連續合約。

## 數據清洗與預處理方法

1.  **缺失值處理**：
    *   **刪除**：如果缺失值佔比很小，可以直接刪除包含缺失值的行或列。但可能導致數據量減少，信息丟失。
    *   **填充 (Imputation)**：
        *   **常數填充**：用0、平均值、中位數或眾數填充。
        *   **插值法**：根據前後數據點進行線性插值、樣條插值或前向/後向填充（如Pandas的`fillna(method='ffill')`）。
        *   **模型預測**：使用機器學習模型預測缺失值。

2.  **異常值處理**：
    *   **識別**：
        *   **統計方法**：基於標準差（Z-score）、四分位距（IQR）等。
        *   **可視化**：箱線圖、散點圖等。
        *   **模型方法**：Isolation Forest, One-Class SVM等異常檢測演算法。
    *   **處理**：
        *   **刪除**：直接刪除異常值。
        *   **修正**：將異常值替換為平均值、中位數或邊界值（Winsorization）。
        *   **不處理**：如果異常值代表真實的極端市場行為，可能需要保留。

3.  **重複值處理**：
    *   **識別**：通常透過數據庫查詢或程式碼（如Pandas的`duplicated()`）來識別。
    *   **刪除**：保留第一條或最後一條記錄，刪除其餘重複項。

4.  **數據標準化/歸一化 (Standardization/Normalization)**：
    *   **標準化 (Standardization)**：將數據轉換為均值為0，標準差為1的分佈（Z-score標準化）。適用於數據分佈近似正態分佈的場景。
    *   **歸一化 (Normalization)**：將數據縮放到特定範圍內（如[0, 1]或[-1, 1]）。適用於需要消除量綱影響的場景。
    *   **目的**：消除不同特徵之間的量綱差異，使模型訓練更穩定，加速收斂。

5.  **時間序列數據的特殊處理**：
    *   **時間戳對齊**：確保不同數據源的時間戳一致，處理非交易時間的數據。
    *   **頻率轉換**：將高頻數據聚合為低頻數據（如從Tick數據生成K線數據），或將低頻數據插值為高頻數據。
    *   **連續合約處理**：對於期貨，需要將不同交割月份的合約數據拼接成一個連續的序列，通常採用**主力合約**或**指數合約**的方式，並處理展期時的跳空。

## 數據預處理的原則

-   **及早處理**：數據問題越早發現和處理，成本越低。
-   **保留原始數據**：在處理數據時，始終保留一份原始未經修改的數據副本。
-   **記錄處理過程**：詳細記錄每一步數據清洗和預處理的過程，便於追溯和重現。
-   **避免未來函數**：在預處理過程中，確保不會引入[[2.3. 回測/2.3.1. 回測偏差與陷阱#未來函數（Look-ahead Bias）|未來函數]]。

高質量的數據清洗與預處理是構建可靠量化策略的基礎。