# 均值漂移 (Mean Shift)

歡迎來到均值漂移 (Mean Shift) 聚類的世界！均值漂移是一種**非監督式學習**聚類演算法，它是一種**非參數 (Non-parametric)** 的方法，不需要預先指定簇的數量。它的核心思想是透過迭代地將數據點移動到其鄰域的平均值（即密度最高的區域），最終收斂到數據分佈的**密度峰值 (Density Peaks)**，每個峰值代表一個簇。

---

## 核心概念

*   **核密度估計 (Kernel Density Estimation, KDE)**：均值漂移的基礎。它是一種非參數方法，用於估計數據點的機率密度函數。透過在每個數據點周圍放置一個核函數（例如高斯核），然後將這些核函數疊加起來，可以估計出數據的整體密度分佈。
*   **帶寬 (Bandwidth, $h$)**：這是均值漂移演算法中最重要的超參數。它定義了在計算局部密度和均值時考慮的鄰域大小。帶寬的選擇對聚類結果有顯著影響：
    *   **帶寬過小**：可能導致過多的簇，甚至將每個數據點視為一個簇。
    *   **帶寬過大**：可能導致過少的簇，將多個獨立的簇合併。
*   **均值漂移向量 (Mean Shift Vector)**：對於一個給定的數據點，均值漂移向量指向其鄰域內數據點的平均值方向。這個向量的方向是密度增加最快的方向。
*   **密度峰值 (Density Peaks)**：數據分佈中局部密度最高的點。均值漂移演算法的目標是讓每個數據點「漂移」到其最近的密度峰值。

---

## 均值漂移的工作原理

對於每個數據點：

1.  **初始化**：將當前數據點作為起始點。
2.  **計算均值漂移向量**：在以當前點為中心、帶寬為 $h$ 的鄰域內，計算所有數據點的平均值。這個平均值與當前點之間的向量就是均值漂移向量。
3.  **移動數據點**：將當前數據點移動到其鄰域的平均值位置。
4.  **重複**：重複步驟 2 和 3，直到數據點收斂到一個穩定的位置（即均值漂移向量的長度小於一個閾值）。
5.  **形成簇**：所有收斂到同一個密度峰值的數據點被歸為同一個簇。

---

## 優點與缺點

### 優點

*   **無需預先指定簇的數量**：這是均值漂移的一個顯著優勢，它會自動發現簇的數量。
*   **能夠發現任意形狀的簇**：由於基於密度，均值漂移可以識別非球形、不規則形狀的簇。
*   **對異常值魯棒**：異常值通常位於低密度區域，不會被漂移到密度峰值，因此不會影響簇的形成。
*   **聚類結果穩定**：對於給定的帶寬，聚類結果是確定的，不會像 K-Means 那樣受到初始化的影響。

### 缺點

*   **帶寬選擇困難**：帶寬 $h$ 的選擇對聚類結果影響非常大，且通常需要經驗和試驗來確定。沒有一個通用的方法來自動選擇最佳帶寬。
*   **計算成本高**：對於大型數據集，尤其是在高維空間中，計算核密度估計和均值漂移向量的計算量非常大，效率低下。
*   **難以處理高維數據**：在高維空間中，數據變得稀疏，密度概念模糊，均值漂移的性能會下降。

---

## 應用場景

*   **圖像分割**：將圖像中的像素點聚類，以區分不同的物體或區域。
*   **物體追蹤**：在影片中追蹤移動的物體。
*   **模式識別**：在數據中發現密度最高的區域。

---

均值漂移是一種強大且靈活的聚類演算法，尤其適用於發現不規則形狀的簇和處理不需要預先指定簇數量的場景。理解其基於密度的原理和帶寬的選擇是掌握它的關鍵。接下來，我們將轉向降維演算法。請持續關注！
