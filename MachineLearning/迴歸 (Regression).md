# 迴歸 (Regression)

歡迎來到迴歸分析的世界！在監督式學習中，當我們的目標是預測一個**連續型數值**時，我們所處理的問題就屬於迴歸問題。

---

## 核心概念

*   **連續型目標變數 (Continuous Target Variable)**：迴歸模型的輸出是一個數值，這個數值可以在一個範圍內取任意值。例如，房價、溫度、銷售額、股票價格等。
*   **特徵 (Features)**：用於預測目標變數的輸入數據。例如，預測房價時，房屋的面積、地理位置、房間數量等都是特徵。
*   **模型 (Model)**：迴歸模型會學習特徵與目標變數之間的關係，並建立一個函數來近似這種關係。這個函數可以用來對新的、未見過的數據進行預測。
*   **誤差 (Error)**：預測值與真實值之間的差異。迴歸模型的目標是最小化這個誤差。

---

## 迴歸的目標

迴歸的目標是找到一個最佳的函數 $f(X)$，使得 $Y \approx f(X)$，其中 $Y$ 是目標變數，$X$ 是輸入特徵。這個函數可以是線性的，也可以是非線性的。

---

## 常見的迴歸演算法

以下是一些常見的迴歸演算法，我們將在後續的節點中詳細介紹：

1.  **[[線性迴歸 (Linear Regression)]]**：最基礎的迴歸模型，假設特徵與目標變數之間存在線性關係。
2.  **[[多項式迴歸 (Polynomial Regression)]]**：當特徵與目標變數之間存在非線性關係時，可以透過引入特徵的多項式項來擬合。
3.  **[[嶺迴歸 (Ridge Regression)]] 與 [[Lasso迴歸 (Lasso Regression)]]**：這兩種是線性迴歸的變體，引入了正則化項 (Regularization) 來防止過擬合 (Overfitting)，提高模型的泛化能力。
4.  **[[決策樹迴歸 (Decision Tree Regression)]]**：透過樹狀結構進行決策，將數據空間劃分為多個區域，每個區域有一個預測值。
5.  **[[隨機森林迴歸 (Random Forest Regression)]]**：由多個決策樹組成的集成學習模型，透過綜合多棵樹的預測結果來提高準確性和穩定性。
6.  **[[支持向量迴歸 (Support Vector Regression, SVR)]]**：支持向量機在迴歸問題上的應用，目標是找到一個函數，使得所有數據點都盡可能地靠近這個函數，並且在一定容忍範圍內的誤差不被懲罰。
7.  **[[梯度提升迴歸 (Gradient Boosting Regression)]]**：如 XGBoost, LightGBM 等，透過迭代地訓練弱預測器（通常是決策樹）並將它們組合起來，逐步提升模型的性能。

---

## 評估指標

評估迴歸模型性能的常見指標包括：

*   **均方誤差 (Mean Squared Error, MSE)**：預測值與真實值之差的平方的平均值。
*   **均方根誤差 (Root Mean Squared Error, RMSE)**：MSE 的平方根，與目標變數的單位相同，更具可解釋性。
*   **平均絕對誤差 (Mean Absolute Error, MAE)**：預測值與真實值之差的絕對值的平均值。
*   **R-平方 (R-squared, $R^2$)**：衡量模型解釋目標變數變異的比例，值越接近 1 表示模型擬合得越好。

---

理解迴歸是許多實際應用中預測連續數值的關鍵。接下來，我們將深入探討各種迴歸演算法。請持續關注！
