# 邏輯迴歸 (Logistic Regression)

歡迎來到邏輯迴歸的世界！儘管名稱中帶有「迴歸」，但邏輯迴歸實際上是一種廣泛用於**二元分類 (Binary Classification)** 問題的線性模型。它的核心思想是將線性模型的輸出透過一個非線性函數（Sigmoid 函數）轉換為機率，從而判斷一個樣本屬於某個類別的可能性。

---

## 核心概念

*   **二元分類 (Binary Classification)**：目標變數只有兩個類別（例如：是/否、真/假、0/1）。
*   **Sigmoid 函數 (或 Logistic 函數)**：這是邏輯迴歸的關鍵。它將任意實數映射到 (0, 1) 區間內，可以解釋為屬於某個類別的機率。
    $P(Y=1|X) = \frac{1}{1 + e^{-(b_0 + b_1X_1 + \dots + b_nX_n)}}$
    其中：
    *   $P(Y=1|X)$ 是在給定特徵 $X$ 的情況下，目標變數 $Y$ 屬於類別 1 的機率。
    *   $b_0 + b_1X_1 + \dots + b_nX_n$ 是線性模型的輸出，也稱為**對數幾率 (Log-odds)** 或 **logit**。
*   **決策閾值 (Decision Threshold)**：通常設定為 0.5。如果預測機率大於或等於 0.5，則將樣本分類為類別 1；否則分類為類別 0。
*   **最大似然估計 (Maximum Likelihood Estimation, MLE)**：邏輯迴歸的參數（係數 $b_i$）不是透過最小化平方誤差來估計的，而是透過最大化似然函數來估計的。似然函數衡量了在給定模型參數下，觀察到訓練數據的機率。

---

## 邏輯迴歸的優點與缺點

### 優點

*   **簡單易懂**：模型相對簡單，易於理解和解釋。係數的指數形式可以解釋為「幾率比」(Odds Ratio)。
*   **計算效率高**：訓練速度快，尤其適用於大型數據集。
*   **輸出機率**：能夠直接輸出樣本屬於每個類別的機率，這對於許多應用場景非常有用。
*   **廣泛應用**：在醫學、金融、市場營銷等領域有著廣泛的應用。

### 缺點

*   **假設嚴格**：假設特徵與對數幾率之間存在線性關係。如果關係是非線性的，模型性能可能不佳。
*   **無法捕捉複雜關係**：對於特徵之間存在複雜交互作用或非線性關係的數據，邏輯迴歸可能表現不佳。
*   **對異常值敏感**：與線性迴歸類似，邏輯迴歸也可能受到異常值的影響。
*   **多重共線性問題**：特徵之間的高度相關性會導致係數估計不穩定。

---

## 應用場景

*   疾病診斷（例如：判斷是否患有某種疾病）
*   信用評分（例如：判斷客戶是否會違約）
*   垃圾郵件檢測（例如：判斷郵件是否為垃圾郵件）
*   市場營銷（例如：判斷客戶是否會購買某產品）

---

邏輯迴歸是分類問題的入門級演算法，理解其原理是掌握更複雜分類模型的基礎。接下來，我們將探討另一種強大的分類模型——支持向量機。請持續關注！
