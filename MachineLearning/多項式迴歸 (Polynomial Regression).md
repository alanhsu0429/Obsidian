# 多項式迴歸 (Polynomial Regression)

歡迎來到多項式迴歸的世界！當數據的特徵與目標變數之間存在**非線性關係**時，簡單的線性迴歸模型可能無法很好地捕捉這種複雜性。多項式迴歸透過引入特徵的**多項式項**，將線性模型擴展到能夠擬合非線性數據。

---

## 核心概念

*   **非線性關係的線性模型**：多項式迴歸的本質仍然是線性模型，因為它將原始特徵的冪次（如 $X^2, X^3$）作為新的特徵，然後對這些新特徵進行線性組合。這使得模型在特徵空間中是線性的，但在原始數據空間中卻能擬合非線性曲線。
*   **模型方程 (Model Equation)**：
    *   對於一個特徵 $X$ 和 $d$ 次多項式：
        $Y = b_0 + b_1X + b_2X^2 + \dots + b_dX^d + \epsilon$
    *   對於多個特徵，可以包含交叉項 (Interaction Terms)，例如 $X_1X_2$。
*   **多項式次數 (Degree of Polynomial)**：這是多項式迴歸的關鍵參數。較高的次數可以擬合更複雜的曲線，但也更容易導致**過擬合 (Overfitting)**。

---

## 多項式迴歸的優點與缺點

### 優點

*   **捕捉非線性關係**：能夠擬合比線性迴歸更廣泛的曲線形狀，適用於特徵與目標變數之間存在彎曲關係的數據。
*   **相對簡單**：在概念上是線性迴歸的自然延伸，易於理解和實現。

### 缺點

*   **過擬合風險**：多項式次數過高時，模型可能會過度擬合訓練數據中的噪聲，導致在未見過的數據上表現不佳。
*   **解釋性下降**：當多項式次數增加時，模型中的係數解釋性不如線性迴歸直觀。
*   **對異常值敏感**：與線性迴歸一樣，多項式迴歸也對異常值敏感。
*   **外推問題 (Extrapolation)**：在訓練數據範圍之外進行預測時，多項式模型可能會產生不合理的結果。

---

## 如何選擇多項式次數

選擇合適的多項式次數是多項式迴歸的關鍵。常用的方法包括：

*   **交叉驗證 (Cross-validation)**：透過在不同的訓練/驗證集上評估模型性能，來選擇最佳的次數。
*   **觀察學習曲線 (Learning Curves)**：分析模型在訓練集和驗證集上的性能，以判斷是否存在過擬合或欠擬合。
*   **領域知識 (Domain Knowledge)**：根據對數據和問題的理解，初步判斷可能存在的非線性關係。

---

## 應用場景

*   生物學中生長曲線的建模
*   工程學中材料應力與應變的關係
*   經濟學中某些非線性趨勢的預測

---

多項式迴歸為我們提供了一種強大的工具來處理非線性數據。然而，我們必須謹慎選擇多項式次數，以避免過擬合。接下來，我們將探討如何透過正則化來改進迴歸模型的穩定性和泛化能力。請持續關注！
