# 聚類 (Clustering)

歡迎來到聚類分析的世界！在非監督式學習中，聚類的目標是將數據點分組，使得同一組（即「簇」或「群集」）內的數據點彼此相似，而不同組之間的數據點則差異較大。這個過程是自動的，不需要預先知道數據的類別標籤。

---

## 核心概念

*   **相似度/距離度量 (Similarity/Distance Measure)**：聚類演算法的核心是定義數據點之間的相似度或距離。常見的距離度量包括歐幾里得距離 (Euclidean Distance)、曼哈頓距離 (Manhattan Distance) 等。
*   **簇 (Cluster)**：由一組相似的數據點組成的集合。聚類演算法的目標是發現數據中的自然簇。
*   **簇中心 (Centroid)**：在某些聚類演算法中，簇中心代表了該簇的平均位置或代表點。
*   **內部緊密度 (Intra-cluster Cohesion)**：同一簇內數據點之間的相似度或距離。理想情況下，簇內數據點應該高度相似。
*   **外部分離度 (Inter-cluster Separation)**：不同簇之間數據點的差異度或距離。理想情況下，不同簇之間應該有明顯的區別。

---

## 聚類的目標

聚類的目標是發現數據中隱藏的、有意義的群組結構，以便更好地理解數據的內在分佈，或作為後續分析的預處理步驟。

---

## 常見的聚類演算法

以下是一些常見的聚類演算法，我們將在後續的節點中詳細介紹：

1.  **[[K-Means 聚類]]**：最流行且廣泛使用的聚類演算法之一。它將數據點劃分為 K 個簇，每個數據點都屬於離它最近的簇中心。
2.  **[[DBSCAN (Density-Based Spatial Clustering of Applications with Noise)]]**：一種基於密度的聚類演算法，能夠發現任意形狀的簇，並能有效處理噪聲點。
3.  **[[階層式聚類 (Hierarchical Clustering)]]**：透過建立一個樹狀結構（樹狀圖 Dendrogram）來組織簇。它可以是凝聚式的（從單個點開始合併）或分裂式的（從一個大簇開始分裂）。
4.  **[[高斯混合模型 (Gaussian Mixture Model, GMM)]]**：一種基於機率模型的聚類方法，假設數據點來自於多個高斯分佈的混合。
5.  **[[均值漂移 (Mean Shift)]]**：一種基於密度的非參數聚類演算法，透過迭代地將數據點移動到其鄰域的平均值來尋找密度峰值。

---

## 評估指標

由於聚類是無監督的，沒有真實標籤可供比較，因此其評估指標通常是基於數據的內部結構：

*   **輪廓係數 (Silhouette Coefficient)**：衡量一個數據點與其自身簇的相似度以及與其他簇的相異度。值介於 -1 到 1 之間，越高表示聚類效果越好。
*   **戴維森-堡丁指數 (Davies-Bouldin Index)**：衡量簇內相似度與簇間差異度的比值。值越低表示聚類效果越好。
*   **卡林斯基-哈拉巴斯指數 (Calinski-Harabasz Index)**：衡量簇間離散度與簇內離散度的比值。值越高表示聚類效果越好。

---

聚類是理解數據結構、發現隱藏模式的強大工具。接下來，我們將深入探討各種聚類演算法。請持續關注！
