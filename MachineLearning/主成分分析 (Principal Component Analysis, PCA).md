# 主成分分析 (Principal Component Analysis, PCA)

歡迎來到主成分分析 (PCA) 的世界！PCA 是一種最廣泛使用的**線性降維**技術，它透過**正交變換 (Orthogonal Transformation)** 將原始數據轉換到一個新的坐標系上，使得新的坐標軸（稱為**主成分 (Principal Components)**）能夠最大化數據的方差。PCA 的目標是在保留數據中最多信息的前提下，減少數據的維度。

---

## 核心概念

*   **方差最大化 (Variance Maximization)**：PCA 的核心思想是找到數據中方差最大的方向。方差越大，表示數據在這個方向上的信息量越多。第一個主成分是數據中方差最大的方向，第二個主成分是與第一個主成分正交且方差次大的方向，以此類推。
*   **正交變換 (Orthogonal Transformation)**：PCA 是一種線性變換，它將原始特徵空間中的數據投影到一個新的、正交的特徵空間中。新的特徵是原始特徵的線性組合。
*   **主成分 (Principal Components, PCs)**：新的坐標軸，它們是原始特徵的線性組合，並且彼此之間是正交的。每個主成分都捕捉了數據中不同方向的變異。
*   **特徵值與特徵向量 (Eigenvalues and Eigenvectors)**：PCA 的數學基礎是計算數據的**協方差矩陣 (Covariance Matrix)** 的特徵值和特徵向量。特徵向量定義了主成分的方向，而對應的特徵值則表示該主成分所解釋的方差大小。
*   **降維 (Dimensionality Reduction)**：透過選擇解釋了大部分方差的前 $k$ 個主成分，我們可以將數據從原始的 $n$ 維空間降到 $k$ 維空間，同時盡可能地保留數據中的信息。

---

## PCA 的工作原理

1.  **數據標準化 (Standardization)**：由於 PCA 對數據的尺度敏感，通常需要對數據進行標準化（使每個特徵的均值為 0，方差為 1）。
2.  **計算協方差矩陣 (Covariance Matrix)**：計算標準化後數據的協方差矩陣。協方差矩陣描述了特徵之間的關係和變異。
3.  **計算特徵值和特徵向量 (Eigenvalues and Eigenvectors)**：計算協方差矩陣的特徵值和特徵向量。特徵值表示每個主成分的重要性（解釋的方差），特徵向量表示每個主成分的方向。
4.  **選擇主成分**：將特徵值從大到小排序，選擇前 $k$ 個最大的特徵值及其對應的特徵向量。這些特徵向量構成了新的 $k$ 維空間的基。
5.  **數據投影 (Projection)**：將原始數據投影到由選定的 $k$ 個特徵向量構成的新空間中，得到降維後的數據。

---

## 如何選擇主成分的數量 (k)

選擇合適的 $k$ 值是 PCA 的關鍵。常用的方法包括：

*   **解釋方差比 (Explained Variance Ratio)**：每個主成分所解釋的方差佔總方差的比例。通常會選擇累積解釋方差達到一定閾值（例如 95%）的主成分數量。
*   **碎石圖 (Scree Plot)**：繪製特徵值（或解釋方差）與主成分序號的關係圖。選擇「肘部」點之前的主成分數量。
*   **領域知識 (Domain Knowledge)**：根據對數據和問題的理解來選擇。

---

## 優點與缺點

### 優點

*   **減少維度**：有效減少數據的維度，降低計算複雜度，提高模型訓練速度。
*   **去除冗餘**：透過將相關特徵組合為新的正交主成分，可以消除特徵之間的冗餘。
*   **去除噪聲**：較小的主成分通常包含較多的噪聲，去除這些主成分有助於提高數據質量。
*   **數據可視化**：將高維數據降至 2D 或 3D，便於可視化和理解數據結構。
*   **提高模型性能**：減少維度災難的影響，有助於提高某些機器學習模型的泛化能力。

### 缺點

*   **線性方法**：PCA 是一種線性降維方法，無法捕捉數據中的非線性結構。
*   **信息損失**：降維總是伴隨著一定程度的信息損失。選擇不當的 $k$ 值可能導致重要信息的丟失。
*   **可解釋性下降**：新的主成分是原始特徵的線性組合，其物理意義可能不如原始特徵直觀。
*   **對異常值敏感**：由於基於方差，PCA 對異常值敏感，異常值可能會影響主成分的方向。

---

## 應用場景

*   **圖像壓縮**：減少圖像數據的維度，同時保留主要信息。
*   **人臉識別**：從人臉圖像中提取主要特徵。
*   **數據可視化**：將高維數據降至 2D 或 3D 進行繪圖。
*   **特徵工程**：作為監督式學習模型的預處理步驟，減少特徵數量。

---

主成分分析是理解和處理高維數據的基礎工具。理解其方差最大化和正交變換的原理是掌握它的關鍵。接下來，我們將探討另一種降維方法——線性判別分析。請持續關注！
