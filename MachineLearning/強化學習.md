# 強化學習 (Reinforcement Learning)

歡迎來到強化學習的世界！這是一個受行為心理學啟發的機器學習範疇，其核心思想是讓一個「代理人」(Agent) 透過與「環境」(Environment) 的互動來學習如何做出最佳決策，以最大化累積獎勵。

---

## 核心概念

*   **代理人 (Agent)**：學習者或決策者。它觀察環境，執行動作，並從環境中接收獎勵和新的狀態。
*   **環境 (Environment)**：代理人所處的世界。它接收代理人的動作，並返回新的狀態和獎勵。
*   **狀態 (State)**：環境在某一時刻的描述。代理人根據當前狀態來決定下一步的動作。
*   **動作 (Action)**：代理人可以在給定狀態下執行的操作。
*   **獎勵 (Reward)**：環境對代理人執行動作後給予的即時反饋。獎勵可以是正面的（鼓勵）或負面的（懲罰）。代理人的目標是最大化長期累積的獎勵。
*   **策略 (Policy)**：代理人從狀態到動作的映射，定義了代理人在特定狀態下應該採取什麼動作。
*   **價值函數 (Value Function)**：評估在某個狀態下，遵循某個策略所能獲得的長期累積獎勵。它幫助代理人判斷哪些狀態是「好」的，哪些是「壞」的。

---

## 學習過程

強化學習的學習過程是一個不斷試錯的循環：

1.  **觀察 (Observe)**：代理人觀察環境的當前狀態。
2.  **決策 (Decide)**：代理人根據其策略，在當前狀態下選擇一個動作。
3.  **行動 (Act)**：代理人執行所選的動作。
4.  **反饋 (Feedback)**：環境根據代理人的動作，給予一個獎勵，並轉移到一個新的狀態。
5.  **學習 (Learn)**：代理人根據收到的獎勵和新的狀態，調整其策略和價值函數，以期在未來做出更好的決策。

---

## 主要挑戰

*   **探索與利用 (Exploration vs. Exploitation)**：代理人需要在探索新的、可能更好的動作與利用已知能帶來高獎勵的動作之間取得平衡。
*   **延遲獎勵 (Delayed Reward)**：許多時候，一個動作的真正好壞要等到很久以後才能體現出來，這使得學習變得更加困難。

---

## 常見演算法 (將在後續節點詳細介紹)

*   **基於價值 (Value-based)**：Q-learning, SARSA, Deep Q-Networks (DQN) 等。
*   **基於策略 (Policy-based)**：REINFORCE, Actor-Critic (A2C, A3C, DDPG, PPO) 等。

---

## 應用場景

*   遊戲 AI (如 AlphaGo、Atari 遊戲)
*   機器人控制
*   自動駕駛
*   資源管理與排程
*   推薦系統

---

接下來，我們將會深入探討強化學習的各種演算法和應用。請持續關注！
